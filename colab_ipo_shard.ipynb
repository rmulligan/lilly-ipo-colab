{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lilly IPO Shard Runner (Colab)\n",
        "\n",
        "This notebook runs a single shard of `build_ipo_pairs.py` and saves output to Google Drive.\n",
        "\n",
        "**Before running:**\n",
        "- Set `SHARD_ID` (00..07).\n",
        "- Decide how you want to transfer the repo + artifacts to Colab (Git clone or Drive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change this to your preferred Drive folder\n",
        "OUT_DIR = '/content/drive/MyDrive/lilly_ipo'\n",
        "!mkdir -p \"{OUT_DIR}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Download repo (and shards) from GitHub if not already present\n",
        "import os\n",
        "REPO_URL = 'https://github.com/rmulligan/lilly-ipo-colab.git'\n",
        "REPO_DIR = '/content/lilly-ipo-colab'\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    !git clone \"{REPO_URL}\" \"{REPO_DIR}\"\n",
        "\n",
        "print('Repo dir:', REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Verify adapter path exists\n",
        "import os\n",
        "ADAPTER_PATH = '/content/drive/MyDrive/lilly_repo/experiments/lilly_subjective_32b/final_lilly_32b'\n",
        "print('Adapter exists:', os.path.isdir(ADAPTER_PATH))\n",
        "print('Adapter contents:')\n",
        "!ls -la \"{ADAPTER_PATH}\" | head -n 20\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Sync adapter from Drive into repo (if missing)\n",
        "import os, shutil\n",
        "DRIVE_ADAPTER = '/content/drive/MyDrive/lilly_repo/experiments/lilly_subjective_32b/final_lilly_32b'\n",
        "REPO_DIR = '/content/lilly-ipo-colab'\n",
        "REPO_ADAPTER = REPO_DIR + '/experiments/lilly_subjective_32b/final_lilly_32b'\n",
        "if os.path.isdir(DRIVE_ADAPTER):\n",
        "    os.makedirs(os.path.dirname(REPO_ADAPTER), exist_ok=True)\n",
        "    if not os.path.isdir(REPO_ADAPTER):\n",
        "        print('Copying adapter into repo...')\n",
        "        shutil.copytree(DRIVE_ADAPTER, REPO_ADAPTER)\n",
        "    else:\n",
        "        print('Repo adapter already exists, skipping copy.')\n",
        "else:\n",
        "    print('Drive adapter not found; please check path:', DRIVE_ADAPTER)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Verify selected shard exists\n",
        "import os\n",
        "SHARD_ID = '00'  # set before running\n",
        "SHARD_PATH = f'/content/lilly-ipo-colab/experiments/affect_ipo/shards/prompts_shard_{SHARD_ID}.json'\n",
        "print('Shard path:', SHARD_PATH)\n",
        "print('Shard exists:', os.path.isfile(SHARD_PATH))\n",
        "!ls -la \"{SHARD_PATH}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Run shard and save to Drive with timestamp\n",
        "import time\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "OUT_PATH = f'/content/drive/MyDrive/lilly_ipo/pairs_shard_{SHARD_ID}_{ts}.jsonl'\n",
        "print('Writing to:', OUT_PATH)\n",
        "!python \"{REPO_DIR}/scripts/build_ipo_pairs.py\" \\\n",
        "  --input \"{REPO_DIR}/experiments/affect_ipo/shards/prompts_shard_{SHARD_ID}.json\" \\\n",
        "  --output \"{OUT_PATH}\" \\\n",
        "  --adapter-path \"{REPO_DIR}/experiments/lilly_subjective_32b/final_lilly_32b\" \\\n",
        "  --probe-path \"{REPO_DIR}/experiments/egist_32b/unified_lilly_probe.pt\" \\\n",
        "  --dimensions-path \"{REPO_DIR}/experiments/egist_32b/unified_dimensions.json\" \\\n",
        "  --classifier-path \"{REPO_DIR}/experiments/lilly_subjective_32b/affect_classifier.pt\" \\\n",
        "  --num-candidates 4 \\\n",
        "  --max-new-tokens 160 \\\n",
        "  --max-samples 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: run all shards sequentially in one session\n",
        "import time\n",
        "ALL_SHARDS = [f'{i:02d}' for i in range(8)]\n",
        "for sid in ALL_SHARDS:\n",
        "    ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "    out_path = f'/content/drive/MyDrive/lilly_ipo/pairs_shard_{sid}_{ts}.jsonl'\n",
        "    print('Running shard', sid, '->', out_path)\n",
        "    !python \"{REPO_DIR}/scripts/build_ipo_pairs.py\" \\\n",
        "      --input \"{REPO_DIR}/experiments/affect_ipo/shards/prompts_shard_{sid}.json\" \\\n",
        "      --output \"{out_path}\" \\\n",
        "      --adapter-path \"{REPO_DIR}/experiments/lilly_subjective_32b/final_lilly_32b\" \\\n",
        "      --probe-path \"{REPO_DIR}/experiments/egist_32b/unified_lilly_probe.pt\" \\\n",
        "      --dimensions-path \"{REPO_DIR}/experiments/egist_32b/unified_dimensions.json\" \\\n",
        "      --classifier-path \"{REPO_DIR}/experiments/lilly_subjective_32b/affect_classifier.pt\" \\\n",
        "      --num-candidates 4 \\\n",
        "      --max-new-tokens 160 \\\n",
        "      --max-samples 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option A: Git clone repo\n",
        "If your repo is accessible via git (public or with credentials), clone it below.\n",
        "Otherwise use Option B to upload a zip or use Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# REPLACE with your repo URL\n",
        "REPO_URL = 'YOUR_REPO_URL_HERE'\n",
        "REPO_DIR = '/content/lilly'\n",
        "# Uncomment if using git\n",
        "# !git clone \"{REPO_URL}\" \"{REPO_DIR}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option B: Use Drive to provide artifacts\n",
        "Place your repo or just the needed files in Drive and set `REPO_DIR` accordingly.\n",
        "Required files:\n",
        "- scripts/build_ipo_pairs.py\n",
        "- experiments/affect_ipo/shards/prompts_shard_XX.json\n",
        "- experiments/egist_32b/unified_lilly_probe.pt\n",
        "- experiments/egist_32b/unified_dimensions.json\n",
        "- experiments/lilly_subjective_32b/affect_classifier.pt\n",
        "- experiments/lilly_subjective_32b/final_lilly_32b (adapter dir)",
        "\n- Adapter already uploaded to Drive at: `/content/drive/MyDrive/lilly_repo/experiments/lilly_subjective_32b/final_lilly_32b`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If using Drive, set REPO_DIR to the folder containing the repo/artifacts\n",
        "REPO_DIR = '/content/drive/MyDrive/lilly_repo'  # change as needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip -q install transformers accelerate bitsandbytes peft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Hugging Face login\n",
        "Only needed if you use gated/private models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Merge all shard outputs on Drive into a single JSONL\n",
        "import glob, os\n",
        "from pathlib import Path\n",
        "OUT_DIR = Path('/content/drive/MyDrive/lilly_ipo')\n",
        "files = sorted(OUT_DIR.glob('pairs_shard_*.jsonl'))\n",
        "print('Found', len(files), 'shard files')\n",
        "merged_path = OUT_DIR / 'pairs_merged.jsonl'\n",
        "with merged_path.open('w') as out:\n",
        "    for f in files:\n",
        "        for line in f.read_text().splitlines():\n",
        "            if line.strip():\n",
        "                out.write(line + '\\n')\n",
        "print('Merged ->', merged_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download merged output\n",
        "In Colab, you can download the merged file directly:\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/lilly_ipo/pairs_merged.jsonl')\n",
        "```\n",
        "Or sync it from Drive to your local machine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done\n",
        "Output will be saved to Google Drive at:\n",
        "`/content/drive/MyDrive/lilly_ipo/pairs_shard_XX.jsonl`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}