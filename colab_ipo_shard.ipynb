{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lilly IPO Shard Runner (Colab)\n",
        "\n",
        "This notebook runs a single shard of `build_ipo_pairs.py` and saves output to Google Drive.\n",
        "\n",
        "**Before running:**\n",
        "- Set `SHARD_ID` (00..07).\n",
        "- Decide how you want to transfer the repo + artifacts to Colab (Git clone or Drive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change this to your preferred Drive folder\n",
        "OUT_DIR = '/content/drive/MyDrive/lilly_ipo'\n",
        "!mkdir -p \"{OUT_DIR}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Persist HF cache to Drive to avoid re-downloading models\n",
        "import os\n",
        "HF_CACHE = '/content/drive/MyDrive/hf_cache'\n",
        "os.makedirs(HF_CACHE, exist_ok=True)\n",
        "os.environ['HF_HOME'] = HF_CACHE\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = HF_CACHE\n",
        "os.environ['TRANSFORMERS_CACHE'] = HF_CACHE\n",
        "print('HF cache set to:', HF_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '0'\n",
        "print('HF_HUB_OFFLINE:', os.environ.get('HF_HUB_OFFLINE'))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: pre-download Qwen3-32B into Drive cache\n",
        "from huggingface_hub import snapshot_download\n",
        "MODEL_ID = 'Qwen/Qwen3-32B'\n",
        "snapshot_download(repo_id=MODEL_ID, cache_dir=HF_CACHE, allow_patterns=['*.json','*.safetensors','*.model','*.txt','*.py','*.tiktoken','tokenizer*','merges.txt','vocab.json'])\n",
        "print('Download complete')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: pre-download embedding model into Drive cache\n",
        "from huggingface_hub import snapshot_download\n",
        "EMBED_MODEL = 'Qwen/Qwen3-Embedding-0.6B'\n",
        "snapshot_download(repo_id=EMBED_MODEL, cache_dir=HF_CACHE)\n",
        "print('Embedding model cached')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Download repo (and shards) from GitHub if not already present\n",
        "import os\n",
        "REPO_URL = 'https://github.com/rmulligan/lilly-ipo-colab.git'\n",
        "REPO_DIR = '/content/lilly-ipo-colab'\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    !git clone \"{REPO_URL}\" \"{REPO_DIR}\"\n",
        "\n",
        "print('Repo dir:', REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Toggle 4-bit quantization (set False if bitsandbytes fails)\n",
        "USE_4BIT = False\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Toggle classifier usage (set False if embedding model is unavailable)\n",
        "USE_CLASSIFIER = True\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Verify adapter path exists\n",
        "import os\n",
        "ADAPTER_PATH = '/content/drive/MyDrive/lilly_repo/experiments/lilly_subjective_32b/final_lilly_32b'\n",
        "print('Adapter exists:', os.path.isdir(ADAPTER_PATH))\n",
        "print('Adapter contents:')\n",
        "!ls -la \"{ADAPTER_PATH}\" | head -n 20\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Sync adapter from Drive into repo (if missing)\n",
        "import os, shutil\n",
        "DRIVE_ADAPTER = '/content/drive/MyDrive/lilly_repo/experiments/lilly_subjective_32b/final_lilly_32b'\n",
        "REPO_DIR = '/content/lilly-ipo-colab'\n",
        "REPO_ADAPTER = REPO_DIR + '/experiments/lilly_subjective_32b/final_lilly_32b'\n",
        "if os.path.isdir(DRIVE_ADAPTER):\n",
        "    os.makedirs(os.path.dirname(REPO_ADAPTER), exist_ok=True)\n",
        "    if not os.path.isdir(REPO_ADAPTER):\n",
        "        print('Copying adapter into repo...')\n",
        "        shutil.copytree(DRIVE_ADAPTER, REPO_ADAPTER)\n",
        "    else:\n",
        "        print('Repo adapter already exists, skipping copy.')\n",
        "else:\n",
        "    print('Drive adapter not found; please check path:', DRIVE_ADAPTER)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Verify selected shard exists\n",
        "import os\n",
        "SHARD_ID = '00'  # set before running\n",
        "SHARD_PATH = f'/content/lilly-ipo-colab/experiments/affect_ipo/shards/prompts_shard_{SHARD_ID}.json'\n",
        "print('Shard path:', SHARD_PATH)\n",
        "print('Shard exists:', os.path.isfile(SHARD_PATH))\n",
        "!ls -la \"{SHARD_PATH}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Check required file paths before running\n",
        "import os\n",
        "REQ_PATHS = [\n",
        "    f'{REPO_DIR}/scripts/build_ipo_pairs.py',\n",
        "    f'{REPO_DIR}/experiments/affect_ipo/shards/prompts_shard_{SHARD_ID}.json',\n",
        "    f'{REPO_DIR}/experiments/egist_32b/unified_lilly_probe.pt',\n",
        "    f'{REPO_DIR}/experiments/egist_32b/unified_dimensions.json',\n",
        "    f'{REPO_DIR}/experiments/lilly_subjective_32b/affect_classifier.pt',\n",
        "    f'{REPO_DIR}/experiments/lilly_subjective_32b/final_lilly_32b',\n",
        "]\n",
        "for p in REQ_PATHS:\n",
        "    print(p, '->', 'OK' if os.path.exists(p) else 'MISSING')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Run shard and save to Drive with timestamp\n",
        "import time\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "OUT_PATH = f'/content/drive/MyDrive/lilly_ipo/pairs_shard_{SHARD_ID}_{ts}.jsonl'\n",
        "print('Writing to:', OUT_PATH)\n",
        "CMD = f\"python {REPO_DIR}/scripts/build_ipo_pairs.py \\\\\n",
        "  --input {REPO_DIR}/experiments/affect_ipo/shards/prompts_shard_{SHARD_ID}.json \\\\\n",
        "  --output {OUT_PATH} \\\\\n",
        "  --adapter-path {REPO_DIR}/experiments/lilly_subjective_32b/final_lilly_32b \\\\\n",
        "  --probe-path {REPO_DIR}/experiments/egist_32b/unified_lilly_probe.pt \\\\\n",
        "  --dimensions-path {REPO_DIR}/experiments/egist_32b/unified_dimensions.json \\\\\n",
        "  --classifier-path {REPO_DIR}/experiments/lilly_subjective_32b/affect_classifier.pt \\\\\n",
        "  --num-candidates 4 \\\\\n",
        "  --max-new-tokens 160 \\\\\n",
        "  --max-samples 100\"\n",
        "if USE_4BIT:\n",
        "    CMD += ' --use-4bit'\n",
        "if not USE_CLASSIFIER:\n",
        "    CMD += ' --no-classifier'\n",
        "!{CMD}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: run all shards sequentially in one session\n",
        "import time\n",
        "ALL_SHARDS = [f'{i:02d}' for i in range(8)]\n",
        "for sid in ALL_SHARDS:\n",
        "    ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "    out_path = f'/content/drive/MyDrive/lilly_ipo/pairs_shard_{sid}_{ts}.jsonl'\n",
        "    print('Running shard', sid, '->', out_path)\n",
        "    CMD = f\"python {REPO_DIR}/scripts/build_ipo_pairs.py \\\\\n",
        "      --input {REPO_DIR}/experiments/affect_ipo/shards/prompts_shard_{sid}.json \\\\\n",
        "      --output {out_path} \\\\\n",
        "      --adapter-path {REPO_DIR}/experiments/lilly_subjective_32b/final_lilly_32b \\\\\n",
        "      --probe-path {REPO_DIR}/experiments/egist_32b/unified_lilly_probe.pt \\\\\n",
        "      --dimensions-path {REPO_DIR}/experiments/egist_32b/unified_dimensions.json \\\\\n",
        "      --classifier-path {REPO_DIR}/experiments/lilly_subjective_32b/affect_classifier.pt \\\\\n",
        "      --num-candidates 4 \\\\\n",
        "      --max-new-tokens 160 \\\\\n",
        "      --max-samples 100\"\n",
        "    if USE_4BIT:\n",
        "        CMD += ' --use-4bit'\n",
        "if not USE_CLASSIFIER:\n",
        "    CMD += ' --no-classifier'\n",
        "    !{CMD}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option A: Git clone repo\n",
        "If your repo is accessible via git (public or with credentials), clone it below.\n",
        "Otherwise use Option B to upload a zip or use Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# REPLACE with your repo URL\n",
        "REPO_URL = 'YOUR_REPO_URL_HERE'\n",
        "REPO_DIR = '/content/lilly'\n",
        "# Uncomment if using git\n",
        "# !git clone \"{REPO_URL}\" \"{REPO_DIR}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option B: Use Drive to provide artifacts\n",
        "Place your repo or just the needed files in Drive and set `REPO_DIR` accordingly.\n",
        "Required files:\n",
        "- scripts/build_ipo_pairs.py\n",
        "- experiments/affect_ipo/shards/prompts_shard_XX.json\n",
        "- experiments/egist_32b/unified_lilly_probe.pt\n",
        "- experiments/egist_32b/unified_dimensions.json\n",
        "- experiments/lilly_subjective_32b/affect_classifier.pt\n",
        "- experiments/lilly_subjective_32b/final_lilly_32b (adapter dir)",
        "\n- Adapter already uploaded to Drive at: `/content/drive/MyDrive/lilly_repo/experiments/lilly_subjective_32b/final_lilly_32b`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If using Drive, set REPO_DIR to the folder containing the repo/artifacts\n",
        "REPO_DIR = '/content/drive/MyDrive/lilly_repo'  # change as needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install deps (requires runtime restart after install)\n",
        "!pip -q install -U transformers accelerate peft \"bitsandbytes>=0.46.1\"\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "print('bitsandbytes version:', getattr(bnb, '__version__', 'unknown'))\n",
        "print('If version < 0.46.1, restart runtime and re-run this cell.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** After installing/upgrading `bitsandbytes`, use `Runtime \u2192 Restart runtime` in Colab, then re-run the notebook from the top."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Hugging Face login\n",
        "Only needed if you use gated/private models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Merge all shard outputs on Drive into a single JSONL\n",
        "import glob, os\n",
        "from pathlib import Path\n",
        "OUT_DIR = Path('/content/drive/MyDrive/lilly_ipo')\n",
        "files = sorted(OUT_DIR.glob('pairs_shard_*.jsonl'))\n",
        "print('Found', len(files), 'shard files')\n",
        "merged_path = OUT_DIR / 'pairs_merged.jsonl'\n",
        "with merged_path.open('w') as out:\n",
        "    for f in files:\n",
        "        for line in f.read_text().splitlines():\n",
        "            if line.strip():\n",
        "                out.write(line + '\\n')\n",
        "print('Merged ->', merged_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download merged output\n",
        "In Colab, you can download the merged file directly:\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/lilly_ipo/pairs_merged.jsonl')\n",
        "```\n",
        "Or sync it from Drive to your local machine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done\n",
        "Output will be saved to Google Drive at:\n",
        "`/content/drive/MyDrive/lilly_ipo/pairs_shard_XX.jsonl`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}